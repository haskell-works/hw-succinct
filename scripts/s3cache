#!/usr/bin/env bash

if [ "$_system_type" == "Darwin" ]; then
  sed () {
    gsed "$@"
  }
fi

cmd="$1"
shift 1

dirs_in() {
  for x in $(find "$1" -mindepth 1 -maxdepth 1 -type d); do
    if [ "$(basename $x | grep -v '^\.')" != "" ]; then
      echo $x
    fi
  done
}

reprefix_dir() {
  echo "$2${3#$1}"
}

s3_bucket_of() {
  if [[ "$1" =~ ^s3://([^\/]+)/ ]]; then
    echo ${BASH_REMATCH[1]}
  fi
}

s3_key_of() {
  if [[ "$1" =~ ^s3://[^\/]+/(.*) ]]; then
    echo ${BASH_REMATCH[1]}
  fi
}

up() {
  remote_archive_prefix="$S3_CACHE_URL"
  mkdir -p "$HOME"/.s3cache
  for x in $(dirs_in $HOME/.ambiata/mafia/packages/1/$(ghc --numeric-version)); do
    local_file="$x"
    local_archive="$(reprefix_dir $HOME/ "$HOME/.s3cache/" $local_file).tar.gz"
    remote_archive="$(reprefix_dir $HOME/ "$remote_archive_prefix/.s3cache/" $local_file).tar.gz"
    if [ "$remote_archive" != "" ]; then
      s3_bucket=$(s3_bucket_of "$remote_archive")
      s3_key=$(s3_key_of "$remote_archive")
      if aws s3api head-object --bucket "$s3_bucket" --key "$s3_key" 2> /dev/null | grep '^{' > /dev/null; then
        echo "Remote already exists: $remote_archive"
      else
        [ -f $local_archive ] || {
          echo "Archiving $local_archive"
          mkdir -p $(dirname $local_archive)
          tar -zcf $local_archive -C $(dirname $local_file) $(basename $local_file)
        }
        aws s3 cp "$local_archive" "$remote_archive"
      fi
    fi
  done
}

down() {
  remote_archive_prefix="$S3_CACHE_URL"
  local_package_prefix="$HOME/.ambiata/mafia/packages/1/$(ghc --numeric-version)"
  local_archive_prefix="$HOME/.s3cache/.ambiata/mafia/packages/1/$(ghc --numeric-version)"
  mkdir -p "$local_archive_prefix"
  mkdir -p "$local_package_prefix"
  s3_bucket="$(s3_bucket_of $remote_archive_prefix)"
  dep_packages="$(./mafia depends)"
  aws s3 ls --recursive "$remote_archive_prefix" | cut -c 32- > /tmp/remote_packages.txt
  for dep_package in $dep_packages; do
    for remote_archive in $(cat /tmp/remote_packages.txt | grep /$dep_package); do
      archive_basename=$(basename $remote_archive)
      built_package="$local_package_prefix/${archive_basename%.tar.gz}"
      built_archive="$local_archive_prefix/${archive_basename}"
      if [ -e "$built_package" ]; then
        echo "Package exists: ${built_package}"
      else
        if [ -e "$built_archive" ]; then
          echo "Archive exists: ${built_archive}"
        else
          aws s3 cp "s3://$s3_bucket/$remote_archive" "$local_archive_prefix/"
        fi
        tar -zxf "$built_archive" -C "$local_package_prefix"
      fi
    done
  done
}

usage() {
  "s3cache (up|down|dirs_in)"
  exit 1
}

case $cmd in
dirs_in)        dirs_in       "$@" ;;
reprefix_dir)   reprefix_dir  "$@" ;;
s3_bucket_of)   s3_bucket_of  "$@" ;;
s3_key_of)      s3_key_of     "$@" ;;
up)             up            "$@" ;;
down)           down          "$@" ;;
*)              usage         "$@" ;;
esac
